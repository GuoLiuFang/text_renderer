{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class gexinghuaRunner:\n",
    "    def __init__(self, image_dir_path=\"\", train_file=\"\", per_img_num=64, conf=\"configs/mix_data.yaml\", corpus_dir=\"data/list_corpus\", o_dir=\"output/mix_train\"):\n",
    "        self.imgdirlist = []\n",
    "        self.imgdirlist.append(image_dir_path)\n",
    "        self.o_dir = o_dir\n",
    "        self.configs = []\n",
    "        self.filelist = []\n",
    "        self.textureList = []\n",
    "        self.filelist.append(train_file)\n",
    "        with open(os.path.join(image_dir_path, train_file), encoding='utf-8') as f:\n",
    "            test_image_list = [str(line).strip() for line in f.readlines()]\n",
    "        for line in test_image_list:\n",
    "            fname = line.split(\" \")[0]\n",
    "            content = line[len(fname):]\n",
    "            content = content.strip()\n",
    "            corpus_f = os.path.join(corpus_dir, fname)\n",
    "            if os.path.exists(corpus_f):\n",
    "                shutil.rmtree(corpus_f)\n",
    "            os.mkdir(corpus_f)\n",
    "            with open(f\"{corpus_f}/{fname}.txt\", \"w\", encoding='utf-8') as tmpf:\n",
    "                tmpf.write(f\"{content}\\n\")\n",
    "            tmpdict = dict(strict=\"\", \n",
    "                           tag=f\"{fname}\", \n",
    "                           num_img=f\"{per_img_num}\", \n",
    "                           config_file=f\"{conf}\", \n",
    "                          corpus_dir=f\"{corpus_f}\",\n",
    "                          fonts_list=\"data/fonts_list/base_chn.txt\",\n",
    "                          corpus_mode=\"list\", \n",
    "                          output_dir=f\"{self.o_dir}\")\n",
    "            tmpimg = Image.open(os.path.join(image_dir_path, fname))\n",
    "            tmp_w = tmpimg.size[0]\n",
    "            tmp_h = tmpimg.size[1]\n",
    "            tmpdict['img_width'] = tmp_w\n",
    "            tmpdict['img_height'] = tmp_h\n",
    "            self.configs.append(tmpdict)\n",
    "            ### 新增纹理信息收集texture..以及bg的。。\n",
    "#             parser.add_argument('--bg_dir', type=str, default='./data/bg',\n",
    "#                         help=\"Some text images(according to your config in yaml file) will\"\n",
    "#                              \"use pictures in this folder as background\")            \n",
    "            # 在这里新建./data/bg_base/fname/然后这里存放内容就好。\n",
    "            if os.path.exists(f\"data/bg_base/{fname}\"):\n",
    "                shutil.rmtree(f\"data/bg_base/{fname}\")\n",
    "            os.makedirs(f\"data/bg_base/{fname}\", exist_ok=True)\n",
    "            tmpimg.crop([0, 0, tmp_w * 0.05 + 1, tmp_h]).convert('RGB').save(f\"data/bg_base/{fname}/1.jpg\")\n",
    "            tmpimg.crop([0, 0, tmp_w, tmp_h * 0.05 + 1]).convert('RGB').save(f\"data/bg_base/{fname}/2.jpg\")\n",
    "            tmpimg.crop([tmp_w * 0.95 - 1, 0, tmp_w, tmp_h]).convert('RGB').save(f\"data/bg_base/{fname}/3.jpg\")\n",
    "            tmpimg.crop([0,tmp_h * 0.95 - 1, tmp_w , tmp_h]).convert('RGB').save(f\"data/bg_base/{fname}/4.jpg\")\n",
    "            self.textureList.append([tmp_w, tmp_h, content, f\"data/bg_base/{fname}\"])\n",
    "            ### table line 和random space个16张。。bg和blur个8张。。。\n",
    "            x1 = dict(strict=\"\", \n",
    "                           tag=f\"{fname}\", \n",
    "                           num_img=f\"{per_img_num}\", \n",
    "                           config_file=f\"{conf}\", \n",
    "                          corpus_dir=f\"{corpus_f}\", \n",
    "                      fonts_list=\"data/fonts_list/base_chn.txt\",\n",
    "                          corpus_mode=\"list\", \n",
    "                          output_dir=f\"{self.o_dir}\")\n",
    "            x1['config_file'] = 'configs/mix_data_line.yaml'\n",
    "            x1['num_img'] = 16\n",
    "            self.configs.append(x1)\n",
    "            # 判断是否含有三个空格，如果\n",
    "            if \"   \" not in content:\n",
    "                x2 = dict(strict=\"\", \n",
    "                           tag=f\"{fname}\", \n",
    "                           num_img=f\"{per_img_num}\", \n",
    "                           config_file=f\"{conf}\", \n",
    "                          corpus_dir=f\"{corpus_f}\", \n",
    "                          fonts_list=\"data/fonts_list/base_chn.txt\",\n",
    "                          corpus_mode=\"list\", \n",
    "                          output_dir=f\"{self.o_dir}\")\n",
    "                x2['config_file'] = 'configs/mix_data_space.yaml'   \n",
    "                x2['num_img'] = 16\n",
    "                self.configs.append(x2)\n",
    "            # 接下来是添加bg和blur，各8张图片。。\n",
    "            x3 = dict(strict=\"\", \n",
    "                           tag=f\"{fname}\", \n",
    "                           num_img=f\"{per_img_num}\", \n",
    "                           config_file=f\"{conf}\", \n",
    "                          corpus_dir=f\"{corpus_f}\", \n",
    "                      fonts_list=\"data/fonts_list/base_chn.txt\",\n",
    "                          corpus_mode=\"list\", \n",
    "                          output_dir=f\"{self.o_dir}\")\n",
    "            x3['config_file'] = 'configs/mix_data_bg.yaml'\n",
    "            x3['num_img'] = 16\n",
    "            x3['bg_dir'] = f\"data/bg_base/{fname}\"\n",
    "            self.configs.append(x3)\n",
    "            # blur 也是8张图片\n",
    "            x4 = dict(strict=\"\", \n",
    "                           tag=f\"{fname}\", \n",
    "                           num_img=f\"{per_img_num}\", \n",
    "                           config_file=f\"{conf}\", \n",
    "                          corpus_dir=f\"{corpus_f}\",\n",
    "                      fonts_list=\"data/fonts_list/base_chn.txt\",\n",
    "                          corpus_mode=\"list\", \n",
    "                          output_dir=f\"{self.o_dir}\")\n",
    "            x4['config_file'] = 'configs/mix_data_blur.yaml'\n",
    "            x4['num_img'] = 16           \n",
    "            self.configs.append(x4)\n",
    "            # 重型mix_mix\n",
    "            x5 = dict(strict=\"\", \n",
    "                           tag=f\"{fname}\", \n",
    "                           num_img=f\"{per_img_num}\", \n",
    "                           config_file=f\"{conf}\", \n",
    "                          corpus_dir=f\"{corpus_f}\", \n",
    "                          corpus_mode=\"list\", \n",
    "                          output_dir=f\"{self.o_dir}\")\n",
    "            x5['config_file'] = 'configs/mix_data_mix.yaml'\n",
    "            x5['num_img'] = 128         \n",
    "            self.configs.append(x5)                    \n",
    "        # 把纹理特征存储起来以供后面使用。。注意程序的border。。\n",
    "        self.df = pd.DataFrame(np.array(self.textureList), columns=['width', 'height', 'char_distribute', 'bg_store'])     \n",
    "        if os.path.exists(\"data/base_texture.pkl\"):\n",
    "            shutil.rmtree(\"data/base_texture.pkl\")\n",
    "        self.df.to_pickle(\"data/base_texture.pkl\")\n",
    "    def __dict_to_args__(self, config: dict):\n",
    "        args = []\n",
    "        for k, v in config.items():\n",
    "            if v is False:\n",
    "                continue\n",
    "            args.append('--%s' % k)\n",
    "            args.append('%s' % v)\n",
    "        return args\n",
    "    def run_gen(self):\n",
    "        self.main_func = './main.py'\n",
    "        # 先做一些清理工作。\n",
    "        if os.path.exists(self.o_dir):\n",
    "            shutil.rmtree(self.o_dir)\n",
    "        for config in self.configs:\n",
    "            args = self.__dict_to_args__(config)\n",
    "            print(\"Run with args: %s\" % args)\n",
    "            subprocess.run(['python', self.main_func] + args)\n",
    "    def merge_result(self, out_suffix=\"_result\"):\n",
    "        self.out = self.o_dir + out_suffix\n",
    "        if os.path.exists(self.out):\n",
    "            shutil.rmtree(self.out)\n",
    "        os.mkdir(self.out)\n",
    "        with open(os.path.join(self.out, \"tmp_labels.txt\"), \"w\", encoding='utf-8') as resultf:\n",
    "            for dir_path, dir_name_list, file_name_list in os.walk(self.o_dir):\n",
    "                if dir_path != self.o_dir:\n",
    "    #                 print(dir_path)\n",
    "                    # 读取文件内容，然后进行复制操作。\n",
    "                    basename = dir_path.split(\"/\")[-1]\n",
    "                    if not basename.startswith(\".\"):\n",
    "                        basename = basename.split(\".\")[0] + \"_\"\n",
    "                        with open(os.path.join(dir_path, \"tmp_labels.txt\"), encoding='utf-8') as f:\n",
    "                            tmp_flist = [str(line).strip() for line in f.readlines()]\n",
    "                        for line in tmp_flist:\n",
    "                            fname = line.split(\" \")[0]\n",
    "                            content = line[len(fname):]\n",
    "                            # 数据两边是不允许加空格的\n",
    "            #                 content = content.strip()\n",
    "                            fname = fname + \".jpg\"\n",
    "                            fname_path = os.path.join(dir_path, fname)\n",
    "                            resultf.write(f\"{basename + fname}{content}\\n\")\n",
    "                            shutil.copy2(fname_path, os.path.join(self.out, basename + fname))\n",
    "        self.filelist.append(os.path.join(self.out, \"tmp_labels.txt\"))\n",
    "        self.__create__()\n",
    "        self.__getIndex__()\n",
    "        self.imgdirlist.append(self.out)\n",
    "    def __create__(self):\n",
    "        self.diclist = []\n",
    "        for file in self.filelist:\n",
    "            with open(file, encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    fname = line.split(\" \")[0]\n",
    "                    tmp = line[len(fname):]\n",
    "                    tmp = tmp.strip().replace(\" \",\"\")\n",
    "                    # 在这里做全角转化为半角的转化\n",
    "                    tmp = tmp.replace(\"（\", \"(\").replace(\"）\", \")\").replace(\"，\", \",\")\n",
    "                    self.diclist.extend(tmp)\n",
    "        self.counter = Counter(self.diclist)\n",
    "        # 把counter转化为字典，存储起来。\n",
    "        self.keys = [' '] + sorted(list(self.counter))\n",
    "        with open(os.path.join(self.out, \"keys.txt\"), \"w\", encoding='utf-8') as kf:\n",
    "            for i in self.keys:\n",
    "                kf.write(i + \"\\n\")\n",
    "    def __getIndex__(self):\n",
    "        for file in self.filelist:\n",
    "            basename = os.path.basename(file)\n",
    "            with open(file, encoding='utf-8') as f, open(file + \"_with_index.txt\", \"w\", encoding='utf-8') as indf:\n",
    "#             with open(file) as f, open(os.path.join(self.out, basename + \"_with_index\"), \"w\") as indf:                \n",
    "                for line in f:\n",
    "                    fname = line.split(\" \")[0]\n",
    "                    content = line[len(fname):]\n",
    "                    content = content.strip().replace(\" \",\"\")\n",
    "                    # 在这里做全角半角的转化。。\n",
    "                    content = content.replace(\"（\", \"(\").replace(\"）\", \")\").replace(\"，\", \",\")\n",
    "                    indf.write(fname)\n",
    "                    for e in content:\n",
    "                        if e != \" \":\n",
    "                            indf.write(\" \" + str(self.keys.index(e)))\n",
    "                    indf.write(\"\\n\")\n",
    "#     def getUniSize(self):\n",
    "        # 去统计图片的数据情况。主要是高和宽。。返回的是，统一以后的长度。。\n",
    "    def resizeImg(self, unih=32, uniw=686, result_suffix=\"_fixresize\"):\n",
    "        # 预测函数，要强行转化为32，686\n",
    "        for img_dir in self.imgdirlist:            \n",
    "            finout = img_dir + result_suffix\n",
    "            if os.path.exists(finout):\n",
    "                shutil.rmtree(finout)\n",
    "            os.mkdir(finout)\n",
    "            # 遍历所有的图片，然后进行resize。。\n",
    "            for file in glob.glob(f\"{img_dir}/*.*\"):\n",
    "                filename = os.path.basename(file)\n",
    "                if '.jpg' in file or '.jpeg' in file:\n",
    "                    # 打开图片然后resize就好。。\n",
    "                    img = Image.open(file)\n",
    "                    img = img.resize((uniw,unih), Image.ANTIALIAS)\n",
    "                    img.convert('RGB').save(os.path.join(finout, filename))\n",
    "                else:\n",
    "                    shutil.copy2(file, finout)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gexinghuaRunner(image_dir_path=\"/Users/guoliufang/Downloads/only_qishui_debug\", \n",
    "train_file=\"/Users/guoliufang/Downloads/only_qishui_debug/label_tmp_guaid_data_produce.txt_debug\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.run_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.merge_result(out_suffix=\"_glf_result_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.resizeImg(result_suffix=\"_glf_fixresize_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read YAML file\n",
    "# with open(\"data.yaml\", 'r') as stream:\n",
    "#     data_loaded = yaml.load(stream)\n",
    "\n",
    "# print(data == data_loaded)\n",
    "\n",
    "import yaml\n",
    "with open(\"configs/mix_data.yaml\", encoding='utf-8') as f:\n",
    "    mix_config = yaml.load(f)\n",
    "print(mix_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mix_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./main.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fonts num: 21\n",
      "Background num: 2\n",
      "Loading corpus from: ./data/list_corpus\n",
      "Load corpus: ./data/list_corpus/rm.txt\n",
      "Load corpus: ./data/list_corpus/common_1201_16.jpg/common_1201_16.jpg.txt\n",
      "Total lines: 2\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/Deng.ttf) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/FZYTK.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STFANGSO.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STSONG.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STZHONGS.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/msyhl.ttc) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/simkai.ttf) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/Dengb.ttf) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/SIMLI.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STKAITI.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STXIHEI.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/msyh.ttc) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/simfang.ttf) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/simsun.ttc) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/Dengl.ttf) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/SIMYOU.TTF) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STLITI.TTF) supported chars(5070) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/STXINWEI.TTF) supported chars(5070) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/msyhbd.ttc) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/simhei.ttf) supported chars(5071) from cache\n",
      "Load font(/Users/guoliufang/Documents/BeiKeWorkSpace/OCR/text_renderer/data/fonts/chn/simsunb.ttf) supported chars(94) from cache\n",
      "Generate text images in ./output/mix_test/default\n",
      "Finish generate data: 7.894 s\n"
     ]
    }
   ],
   "source": [
    "%run -i main.py  --strict --config_file=\"configs/mix_data_line.yaml\" --num_img=128 --img_height=59 --img_width=196 --corpus_mode=\"list\" --corpus_dir ./data/list_corpus  --output_dir ./output/mix_test/\n",
    "# %run -i main.py  --config_file=\"configs/mix_data.yaml\" --num_img=40 --length=22 --img_height=31 --img_width=514 --corpus_mode=\"list\" --corpus_dir ./data/list_corpus  --output_dir ./output/mix_test/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --bg_dir ./data/bg_base/common_1209_16.jpg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yuyiBusinese:\n",
    "    def __init__(self, textture_p='data/base_texture.pkl', busi_p=\"b.txt\"):\n",
    "        # 第一步拉取纹理特征\n",
    "        # 第二步，读取业务数据。。\n",
    "        # 第三步：业务数据的处理分为两种模式。。3.1 直接全部搞。。。3.2 进行分词拓展搞。。。\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
